{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ch = 3\n",
    "hidden_ch = 128\n",
    "out_dim = 10\n",
    "device_id = 0\n",
    "device = 'cpu' if device_id == -1 else f'cuda:{device_id}'\n",
    "n_epochs = 10\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1e267ea6df0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgQ0lEQVR4nO2da2yc55Xf/2du5PB+ES8SSYm0RFmWL5JtRbFrN3Hi3a03XSDJh2QToAujCNb7YVM0wPaDkQJNin5JF00WQVEEUBpjvdtcHDQx4rRudl3DgeNkfZEcXa27REkUKZIS7/e5nH7gCJCd5/+SFsmhmvf/AwgOn8Mz7zPPvGfemec/5xxzdwghfv9JbPQEhBDlQcEuRExQsAsRExTsQsQEBbsQMUHBLkRMSK3G2cyeAvBtAEkA/93dvxH1/02Ndd65pSVom56a4scpFoPj6RR/rSrmF6ltMRe+PwBAgt9nKhlerkIhz33SaWrLVlVR29zMNLXlcvyxGTMkqAWLeT7/udkctWUr+WNjjzuV4Y8Zzh9XEnyOBefzWGDTN74elVUZaivmFvixZrkt4plBurIyPF7BH1duIbxWN8amMDUzHzzYbQe7mSUB/DcAfwigH8A7ZvaSu7/HfDq3tODnL/x10PbGa6/RY6Vnwyd+R0uW+kxdH6C2wWv8hcUztdTW0NAQHJ+cuEF92jrbqe2+Bz9CbcffeoPaBvv7qS2RDI9bJT/Zro6OUtuRg0PUdv+9/LG1todtjV0PUp9iro/aGnyC2qYWW6nt4kj4cRfSZKEA7NrTRW3zA5eo7ezhc9TmxkNt8867g+MdO7ZQn8HzfcHx//Rff0Z9VvM2fj+Ac+5+wd0XAfwIwKdXcX9CiHVkNcHeAeDKLX/3l8aEEHcgqwn20Puj3/nurZk9Y2YHzezg6NjkKg4nhFgNqwn2fgC3frjpBPA7H5Td/YC773P3fU2Ndas4nBBiNawm2N8B0GtmPWaWAfAFAC+tzbSEEGvNbe/Gu3vezL4M4B+wJL095+4nonwWczlcHQzvJG+9dyf1u3joUHC8/yrfle7tCEt8ADA2Ns+PNcDvs+/SheB4lETS2buV2ibn+A7zidNHqS1VqKa2qcm54PjjT26jPlVh5QcA0PAw3+mu3FRBbaO5meD4/BDfzW6r42s1Ps/XY3pxkNqqq9uC44UiV2QGjvGPm1MjV6jtRsTH1E/+8ceorX1Lb3D87OQ49ck0hbNVLcWzWFels7v7ywBeXs19CCHKg75BJ0RMULALERMU7ELEBAW7EDFBwS5ETFjVbvyHZXJ8HL/4afiL+v/yTz9P/R5+LCxbXDjMk0WskifJbOnpprZJ469/ly+Hk2sKi1zuyOW5LDc8EpbJACBTuYnainMRGVuZcMbWqTd5kkZLTSO1tdbyxKCJXIHasumwnheVjTi7wKXIbZ1N1DZ6NiyJAkBdU/gb3E01m6nP5dP8/rraw1IeANx9715qG54aoba3fn4sbEjVUJ9/8cTjwfGKJJdDdWUXIiYo2IWICQp2IWKCgl2ImKBgFyImlHU3vrCQx8Tl60Hbi997gfr9q3/zTHD8/n/+BPW5euJdaqsmdfAAwCJKNKVqyU4nLXQGHD/Fc4Pm8rzW2ehFXlaro5HvkDd3hHetB/r5Lm1unu+QN9cPU9vW1k5qAxEhsg18N3uAJPEAQDrL1YmeHr5rffpcOElm9jpPhLnrLl6DxUk9RAA4fO4UtU0Vxqnt/t7twfG6el4e6+LJi8HxhTn+XOrKLkRMULALERMU7ELEBAW7EDFBwS5ETFCwCxETyiq9OQxFosnMjPDWOT848D+C41/4139KfUZzXI7pP84THeYWeacQpMLJHRNjEa2aUlwKmZwZp7Zkhr8OP/zxj1KbVYXXt+sBXtn3yOFwjT8AOHORr1XC+ePu2BWuedfZy7vgZEbDdesA4Hr/VWrbVM9luQd6w8/Z4gx/XsbGuNx49VpYOgaAkWku51W1RbQB2xyWRVuS9dRndmQ8OJ4wnpSlK7sQMUHBLkRMULALERMU7ELEBAW7EDFBwS5ETFiV9GZmfQCmABQA5N19X9T/J1NJVDeG6511tfA2Q1X14dekF3/wI+qztXc3tS0Wq6htYOAGtU0Mh+XBYo5nlF0Z5lJNQz2Xw1qbI2SXJK/91ljdHBxvq+N15moq+NN2o4/XaksluXxVRTLiXnub1FsDcP5YH7V1tDZQW3ZHO7VNTowHx2cmeb27qWn+uCpr+Dye/Oij1Jav5C3HhobDmZFb2ng7rN57dwTHK7P8XFwLnf0T7s7PaCHEHYHexgsRE1Yb7A7gH83skJmFK0wIIe4IVvs2/jF3HzCzVgCvmNkpd3/91n8ovQg8AwB1Ub2BhRDryqqu7O4+UPo9DOBFAPsD/3PA3fe5+76qSv79YCHE+nLbwW5m1WZWe/M2gD8CcHytJiaEWFtW8za+DcCLZnbzfn7g7r+IcqiszOCenWFJZnt3A/Ubn5kMjg+OzlKfwsIYtZ06cZ7aRoZ5JpeTNk9t7VzKa8hwmy9WU9vMNM+8unCGt3JqbQpLh/NNvEjlpgiZr2U3l0Rz87wN1Zu/DRdfPPTeWeozP8mzxrzAC1VeHQwXXwSAiYmwxPbIRx6kPp94bC+15Z2HTGWWf0w9dPiX1GYkA+/M6BHq07opHEe5HJcNbzvY3f0CgD236y+EKC+S3oSICQp2IWKCgl2ImKBgFyImKNiFiAllLThZWZnGrt3hPlrnTh+lfsdPXQuOp6u5rHX67BlqswTPDEom+ZIUUuHMpWwdl1y2NHHp6voAl5rSrFkagESRS2W92x8Oji/O8yyvQ4e4xJPOcHltYYbb3rsSzo3K5XnGXnU1X0dL8kKgMzO8yOLIeFiKevcYz76rqeXnQFMTz0S79DaXAI//9m1q6+wO9x6srOLnaaYinDFpCb5OurILERMU7ELEBAW7EDFBwS5ETFCwCxETyrobPze/iBOnwjuWZ94bpH5XhsNtgbru5rXH0hE7mYlJ3mqqaxv3W5gPJ5k0NPE6bS0tXdQ2NvJraivM8d34gat8Z/3Xb4brmU3O8tZK5y8OUFsy4nLg83lqm7HwTv38IvdBRGJNpiKcDAUAu3Z3U1u+NZwQ1dTEk6hGR09T2/GT3DYVkUSVLPLHtqXpruB4tjpLfU6cDidDzc/zc1tXdiFigoJdiJigYBciJijYhYgJCnYhYoKCXYiYUFbpbXp6Hr/+J5agUqR+ndt7guMPPfYx6vO//88r1HblIq/hdl8vl/OAueDoKSInAsCZU0PUVizwOnOY47JL0XkCzalLYRktH/G6HqWG5edz1NZcl6G2bGO45l2+yA+WS3I5bHqOy1qX+8KJUgBQXROWUitSPIlq67Yt1DY+eYXainVcLt3ZvZfaLBNOXrk2xo+1aOFzsQieaKQruxAxQcEuRExQsAsRExTsQsQEBbsQMUHBLkRMWFZ6M7PnAPwJgGF3v6801gTgBQDdAPoAfN7deb+lEslMCvWbw218slVcaqquDrdJ+s2v3qE+F85eoLa2Bn6s+alwnTkAmJ8Ly1AzsyPUJ5ngddWylQ3UNuc8e6m+rpH7jYYlmYRxCS1R5HJNVNZbMclltPxC+Hj5iKysYsQcU5mIpqCJiHp9FpbY3jsdrpEHABNTfdR2d3cTtXVvbqa2sTm+xuPT4XXcsWMH9bl8NdxGKxnxhK3kyv63AJ76wNizAF51914Ar5b+FkLcwSwb7KV+66MfGP40gOdLt58H8Jm1nZYQYq253c/sbe4+CACl37xeshDijmDdN+jM7BkzO2hmB+fmeDtZIcT6crvBPmRmmwGg9Jt+ydvdD7j7Pnffl83y71ILIdaX2w32lwA8Xbr9NICfrc10hBDrxUqktx8CeALAJjPrB/A1AN8A8GMz+xKAywA+t6KDpdJoag9/vM/N8hY+r796KDg+MRmWmQCgqYW3SEpwFQT9V8apLZ0KSzzFAs/Y8wSXmiLqNcKL3C8/wz8OJfLhueQj5pFK85ZB5tyWSXPJi0lvlRl+yi3m+DpGSW/pLJfs0jVh2bbCwhIwAIxc47KcTV+itof2clnu0b33U9sMqQV643q4wCkA1Nd2B8dTybeoz7LB7u5fJKYnl/MVQtw56Bt0QsQEBbsQMUHBLkRMULALERMU7ELEhLIWnJyYmMHLPw9LA4k818MqkmFJpq2RFw1MgEtNkxO8eGEqw7/4U0FstZVheQcAKir4EmcibOkUv8+kc5ny+o1w1p5HHCuR4f3t0gmeIVgXUXByYjysJ83M8GKZNTVc5qtr4NmDeXANs74hnIlWmeZrOHK1n9rmF3hW5JtvvElti3NczmtsqQmO11Vvpz61leEirKlURI9DahFC/F6hYBciJijYhYgJCnYhYoKCXYiYoGAXIiaUVXrzQhG5yXA/r+osf91pbgpLMskE7w02v8Clt7oankGVzXKpaYH0PUtFZH8ZkQ0BIFfgWXvTLBUKQFUm3EcNAPLF8Dp6LiLVr8Clq1SWryOTIgGgsSEsi6ZS/DkrFiIy/Rb4+ZGPKJjpC+FSCx3tm6jPlhbe6y0ZsVaTQzz7bnqCz78iGQ7DVJHLfLW14XVMGD/fdGUXIiYo2IWICQp2IWKCgl2ImKBgFyImlHU3viqbxJ77GoI2Vt8NACpIjbHRMb6zm0iGkwsAwHgOBGbH+Y7w7Hy49tv0dERLo4jd23Q6IhEmbdQ2keDJJLPEVIxoJ5VI8AQUB99hnp/hakI6Hd6NryKtvAAgt8h31Qev8RZbO3a0U9snP9YdHK+u4UrC6TM8UcoK/Lza0c3rzC1EnCNz04PB8ZFR/jznSV5QPiKhTFd2IWKCgl2ImKBgFyImKNiFiAkKdiFigoJdiJiwkvZPzwH4EwDD7n5faezrAP4cwE095Kvu/vJy95WuqERHz86g7cZQWH4AgOmpcELA1DSXtRxcX8svclkrkeBLUtMQll3m5iJaKyX5sRrruAxlEXXVkmn+Gl1VEbbNz/N55Ir8WIWIGnQDw+PUVlMZlinnF3ndwNpaLr/ueThccw0AdvT2Utu7Ry8Hx89eukZ9Bod5EtInPsobIVWk+PMycmOM2i5ePhYcf/SJR6hPijRJtQSfw0qu7H8L4KnA+N+4+97Sz7KBLoTYWJYNdnd/HcBoGeYihFhHVvOZ/ctmdtTMnjOzxjWbkRBiXbjdYP8OgO0A9gIYBPBN9o9m9oyZHTSzg7MRn22FEOvLbQW7uw+5e8HdiwC+C2B/xP8ecPd97r6vKssL2Ash1pfbCnYz23zLn58FcHxtpiOEWC9WIr39EMATADaZWT+ArwF4wsz2AnAAfQD+YkVHswSQCctXo5P8LX4S4XcEnuAZPhaRNZZMcIknGZF9l7OJ4HhjC1/GlPGMsvpqPseUcYlqaDAi2y8VXseWdp7lVdfYQm0DVyepbSrPa6T1dNUHx6tqI9prNfKtH09zv5d/dZTazp0LZ8uNTfLrXNL5OVDl/Fj3bL1Ebd1b+WP7+P5wtlx9LT8HRkfCUnUxz7MUlw12d/9iYPh7y/kJIe4s9A06IWKCgl2ImKBgFyImKNiFiAkKdiFiQlkLTqbTKWzeEm67038lLNUAQIGoCYUFLr3t6O2ktqosP9aN6+PUVl1NWgbleJZUTZZUBgRw7tQpaquviWrxxAsRtreG5ZqWzVzGmSAtuQBgUxvPemtt5Vl7lemwXDob0ZbryLF+ajt18Tq1zc9FSLAIr78XuZSXyfM5To3y7Mz6XXytGqv5HLf2bAuO35jh0qZVNoQNEVmburILERMU7ELEBAW7EDFBwS5ETFCwCxETFOxCxISySm/5XA7DA2HpYp70UQOAXD48zUKRZ5TlCvz+aup5VtPYBJddahvC0kpNlmc0VVXwJd68eQ+1XR8eoLZdpF8eAGxqDc8lkeKyULqC3191SxO1vfmbI9Q2ORpe49OX+PNy8nxU9TMulSUjevcZaezXvImfAz0dRGIFcE8XX49de/dS27a7tlNbvjIsU1bV8weWyIWlvGQFf551ZRciJijYhYgJCnYhYoKCXYiYoGAXIiaUeTc+j7FrN4K24iJPFJicCSdqdHR0UJ/piSFqy7XwpJB8nidcjIyEd3AvTxWpT3MDT4TZ1Mir7TY18x1hK/DX6LmpuuD4tu28fVJjxHokq/jubnM9r103Ox5WNSYneXJHltQaBIA0Iur1JXn7qs6OcELRP/v4w9Snu7eL2jY18gSlzi7ehur8eZ5Ac/Xi4eB4VTZcrxEArvRfCY5PT/CagbqyCxETFOxCxAQFuxAxQcEuRExQsAsRExTsQsSElbR/6gLwdwDaARQBHHD3b5tZE4AXAHRjqQXU5919LPreHEWEJZmKNJ9Kfi5ccy2b4okwN8a5HDY5xmW+3dt3UdvC7HRw/N2+q9Tn1GHeEghpnoyRjUigWSzw+RcLYYlqz55wGyQA+MMn76W2uioueY2OcJnnrXf7guPTY/wUaUhzCbCCP9VoaOB+PZ1hqayjJSxRAkAm4mBu/Hl59R9+RW0Xz71Nbbu2hiXkqTE+j+xcWMJMOD83VnJlzwP4K3e/B8AjAP7SzHYDeBbAq+7eC+DV0t9CiDuUZYPd3Qfd/d3S7SkAJwF0APg0gOdL//Y8gM+s0xyFEGvAh/rMbmbdAB4E8BaANncfBJZeEAC0rvnshBBrxoqD3cxqAPwEwFfcnX9Y+12/Z8zsoJkdnIsoUCGEWF9WFOxmlsZSoH/f3X9aGh4ys80l+2YAwyFfdz/g7vvcfV+2klcbEUKsL8sGu5kZlvqxn3T3b91iegnA06XbTwP42dpPTwixVqwk6+0xAH8G4JiZHS6NfRXANwD82My+BOAygM8te7C0YVNbOAtseLiP+s2TNjiz07xt0bbu3dR25uwFarN5npXVTnYlutu4PNWIBmobnud+Qzf4J6Vikvt5Ivz63T/IswCvDmyhtgsLXLK7dJVnCE6PheXS+3p4DbfKJM8QrKqLkNd6tnJbd7i1Usdd4XEASNXwY/3fX7xCbRP9XGbtaeaPbWxmglh41ls+F870KzqvW7dssLv7GwDNL3xyOX8hxJ2BvkEnRExQsAsRExTsQsQEBbsQMUHBLkRMKGvByQQcVclc0FZXEx4HgHQmLDMMDvEMqrvu4dJbTR2XjDyil9AiwrbcHJfJHt/dRm1oaKam8QX+Opx2Lg8uJsIFIi8OBb/ztGS7zKXIXJEXcxy/eo3a9m4OZ5v9wZN3U5/KWv6N60yWF3qsr+d+E5Phb20OXRunPucv/prarvWdoLaeZl4AdZEUTQWAeZJll+H1N3FjIly4NR+REakruxAxQcEuRExQsAsRExTsQsQEBbsQMUHBLkRMKKv0triQw+Vz4Z5XLU08GypH1LAjxyP6Z0VkIO25/z7ud+UktY1Mh2Wc6SLPkppZDBfYBICaBLdt6+IyTmG0n9pOEzks4bx44cT4HLWljUs5uzbzfnR7dj0QHG/d0U59mlp4sc8kKaQJADfGuJQ6uxC2keRAAEBVBV+PXd1cSp0b5pJobo6v46b6sMZWXxex9m2dwfEXf8WlQV3ZhYgJCnYhYoKCXYiYoGAXIiYo2IWICWXdjV9YAC72hXcYsyM8qaWS1B9rauB1vS5f4LuSafCkmxujPGEkWRM+njtP0hgv8oq6dRnegmhxiu/UHzvJ68mdHZgJG6paqM/4FF8PXwzXkgOAh3dxxaC6pTE4Xte8mfoseoSqMcXPj8Zm/thmpsaD45evnqY+YyN87ZNTfKe+o5Unu1jEObJlaziRp66G3x8QVoYiuqjpyi5EXFCwCxETFOxCxAQFuxAxQcEuRExQsAsRE5aV3sysC8DfAWgHUARwwN2/bWZfB/DnAG72B/qqu78cdV/FomF2NixFTcwQyQhAd30xOP7oR3dSn5Hro9Q2OHCF2mrrG6htZ284UePMES7zTc/wGm5XLnGZb3SQJ7tYPa9dl8+E5cEbfDkwOcETLnLOrwcHz/MElIXEseD4J2p4Qsvg5Blqm57iSSZtNXw9Ll/oC45fH+PyZZLUGgSArk6esNV8d7j+HwAkUvw++86H59IBLi3X1IRD12nzppXp7HkAf+Xu75pZLYBDZnaz4dXfuPt/WcF9CCE2mJX0ehsEMFi6PWVmJwHwb1MIIe5IPtRndjPrBvAggLdKQ182s6Nm9pyZhb8yJYS4I1hxsJtZDYCfAPiKu08C+A6A7QD2YunK/03i94yZHTSzg7kC//wqhFhfVhTsZpbGUqB/391/CgDuPuTuBXcvAvgugP0hX3c/4O773H1fOlnWr+ILIW5h2WA3MwPwPQAn3f1bt4zfmtHwWQDH1356Qoi1YiWX2scA/BmAY2Z2uDT2VQBfNLO9ABxAH4C/WO6O0pkE2rtqgrYr4W42AID5XFh6S4BnJ9U1hI8DAKOklhwAFBPhYwHALJEH085lQ8zxLKmRcS4ndXU0UFv7Dl77bWxuIjh+uZ+3qEpEfLyqr+W163KL/PQ5cuJycLyxhfskU9x2+iSXS6sS3G9755bg+J77+R5zbUea2uqbePbalSvhxwwAp357kdp6Oh8Njp/r55l+o9fD0uzkNI+JlezGvwEExbtITV0IcWehb9AJERMU7ELEBAW7EDFBwS5ETFCwCxETyvotl+rqLB7ZH84cu3uCS16Hjh4Njp85O059du/hGXGtbfxY14d4JtfZ98Lz6OB1I7E7ol1QJsEzlNLOJbt8RLum1HQ4k64iP86PleIyZZLXogQK3FjXHJaoFopcukov8Hm01PLMvMZmLjc1dIVP8YVaXszx+sgItVWcpSZM9XNJd/fWfdwRYXlzeIjPo7BAjlXk2XW6sgsRExTsQsQEBbsQMUHBLkRMULALERMU7ELEhLJKb/n5eQyfDGsXvsgzwLbVhLOQTvXzgo1DLbzCYmsHzxqbneAZbAOn+oLjW9vrqU9lD+9flq7m2VUVSe5XKFRT2+OPhh/bA/v5sfLGJa/xaS5RjV4fpLbGmvAcM+CPa2Scpz5WtXK5FE3cdq0QPg9SQ1zKq4soblmc5PLaXTt3Uxua+HM2dimcLddUyx9X247u4Hj2l+epj67sQsQEBbsQMUHBLkRMULALERMU7ELEBAW7EDGhrNJbwh1VhbB0UZHmkkZrJelrVeQyzqVzXIIoFHdQW0NjJ7VV9IR7byVmeTHHs5emqC3RwHt51Uf0RMuAy4MV9eFeZPXVXF7LGS8q2RhR+HL/I+EMRgBwUmgzXcWfs2uJcLFMAHjnxNvUZhGFLz/Z82BwvCbi1C86PxfTCZ5Vlqrlazw8wzMVt+55IHx/eZ7NZ8mK4HhF5RvUR1d2IWKCgl2ImKBgFyImKNiFiAkKdiFiwrK78WZWCeB1ABWl//+f7v41M2sC8AKAbiy1f/q8u/N+NQAylUl07QwXbPPFLJ8Dqbe1vYq/Vo3P8/po50+FW+cAQGNbC7X19ITryQ1fGKc+MD7HpoikkMUpnoByaegStRVI4kcinaE+luG7z1t3cnViaojv4g9PheunFZqpCxYm+DymzkxT2/g4Txh57b3fBMfra/nzkqnjSSuFFH/M14bHqQ0Fvv4NDeHjtTby3f1F0rFrZpbv4K/kyr4A4JPuvgdL7ZmfMrNHADwL4FV37wXwaulvIcQdyrLB7kvcfFlNl34cwKcBPF8afx7AZ9ZjgkKItWGl/dmTpQ6uwwBecfe3ALS5+yAAlH63rtsshRCrZkXB7u4Fd98LoBPAfjO7b6UHMLNnzOygmR2cnOWfyYQQ68uH2o1393EAvwTwFIAhM9sMAKXfwbIx7n7A3fe5+766Kr5JIYRYX5YNdjNrMbOG0u0sgD8AcArASwCeLv3b0wB+tk5zFEKsAStJhNkM4HkzS2LpxeHH7v6/zOyfAPzYzL4E4DKAzy13R+l0Eu0d4USN+VkuNSEXfvufmOO1wj5SxaW8vgEuy3kiIglifig43tjYQH06OvhWRm2RP+apMf7YquraqW1sKpyo0d7Mk262bud62GyCy1rnx69Qm2XD80hO8Xd3XcZlz62dvG7gYJbXG7REuNbclq1bqc90RNLK8AR/zuYmuF+iyBOibpBEKpvnfcUa2fPpvLbessHu7kcB/E7qkLvfAPDkcv5CiDsDfYNOiJigYBciJijYhYgJCnYhYoKCXYiYYO68ptaaH8xsBMDNlK1NAK6X7eAczeP9aB7v5/+3eWxz96CGWdZgf9+BzQ66+74NObjmoXnEcB56Gy9ETFCwCxETNjLYD2zgsW9F83g/msf7+b2Zx4Z9ZhdClBe9jRciJmxIsJvZU2Z22szOmdmG1a4zsz4zO2Zmh83sYBmP+5yZDZvZ8VvGmszsFTM7W/rduEHz+LqZXS2tyWEz+1QZ5tFlZq+Z2UkzO2Fm/7Y0XtY1iZhHWdfEzCrN7G0zO1Kax38sja9uPdy9rD8AkgDOA7gLQAbAEQC7yz2P0lz6AGzagON+DMBDAI7fMvbXAJ4t3X4WwH/eoHl8HcC/K/N6bAbwUOl2LYAzAHaXe00i5lHWNQFgAGpKt9MA3gLwyGrXYyOu7PsBnHP3C+6+COBHWCpeGRvc/XUAH0zCLnsBTzKPsuPug+7+bun2FICTADpQ5jWJmEdZ8SXWvMjrRgR7B4Bbqx70YwMWtIQD+EczO2Rmz2zQHG5yJxXw/LKZHS29zV/3jxO3YmbdWKqfsKFFTT8wD6DMa7IeRV43IthDvYg3ShJ4zN0fAvDHAP7SzD62QfO4k/gOgO1Y6hEwCOCb5TqwmdUA+AmAr7g774Nd/nmUfU18FUVeGRsR7P0Aum75uxPAwAbMA+4+UPo9DOBFLH3E2ChWVMBzvXH3odKJVgTwXZRpTcwsjaUA+767/7Q0XPY1Cc1jo9akdOxxfMgir4yNCPZ3APSaWY+ZZQB8AUvFK8uKmVWbWe3N2wD+CMDxaK915Y4o4HnzZCrxWZRhTczMAHwPwEl3/9YtprKuCZtHuddk3Yq8lmuH8QO7jZ/C0k7neQD/foPmcBeWlIAjAE6Ucx4Afoilt4M5LL3T+RKAZiy10Tpb+t20QfP4ewDHABwtnVybyzCPx7H0Ue4ogMOln0+Ve00i5lHWNQHwAIDflo53HMB/KI2vaj30DTohYoK+QSdETFCwCxETFOxCxAQFuxAxQcEuRExQsAsRExTsQsQEBbsQMeH/AU5VbE84BSGDAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(trainset.data[228])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 5000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, valset = random_split(trainset, [45000, 5000])\n",
    "len(trainset), len(valset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_ch, output_ch, identity_downsample=None, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_ch, output_ch, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(output_ch)\n",
    "        self.conv2 = nn.Conv2d(output_ch, output_ch, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(output_ch)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet18(nn.Module):\n",
    "    \n",
    "    def __init__(self, image_channels, num_classes):\n",
    "        \n",
    "        super(ResNet18, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        #resnet layers\n",
    "        self.layer1 = self.__make_layer(64, 64, stride=1)\n",
    "        self.layer2 = self.__make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self.__make_layer(128, 256, stride=2)\n",
    "        self.layer4 = self.__make_layer(256, 512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def __make_layer(self, in_channels, out_channels, stride):\n",
    "        \n",
    "        identity_downsample = None\n",
    "        if stride != 1:\n",
    "            identity_downsample = self.identity_downsample(in_channels, out_channels)\n",
    "            \n",
    "        return nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels, identity_downsample=identity_downsample, stride=stride), \n",
    "            ResidualBlock(out_channels, out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x \n",
    "    \n",
    "    def identity_downsample(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1), \n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(3, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12562698"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count trainable parameters of the model\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#move the model to the device\n",
    "model.to(device)\n",
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define everything we need for training\n",
    "epochs = 5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=1e-4)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=50):\n",
    "    \n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        for phase in ['train', 'val']: # Each epoch has a training and validation phase\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]: # Iterate over data\n",
    "                \n",
    "                inputs = transforms.functional.resize(inputs, (112, 112))\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad() # Zero the parameter gradients\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'): # Forward. Track history if only in train\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == 'train': # Backward + optimize only if in training phase\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            \n",
    "            if phase == 'val': # Adjust learning rate based on val loss\n",
    "                lr_scheduler.step(epoch_loss)\n",
    "                \n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 1.4662 Acc: 0.4744\n",
      "val Loss: 1.1806 Acc: 0.5728\n",
      "\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 1.0657 Acc: 0.6184\n",
      "val Loss: 0.8607 Acc: 0.7036\n",
      "\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.8439 Acc: 0.7016\n",
      "val Loss: 0.6792 Acc: 0.7650\n",
      "\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.6559 Acc: 0.7680\n",
      "val Loss: 0.5311 Acc: 0.8194\n",
      "\n",
      "Epoch 4/4\n",
      "----------\n",
      "train Loss: 0.4911 Acc: 0.8284\n",
      "val Loss: 0.3903 Acc: 0.8634\n",
      "\n",
      "Training complete in 5m 48s\n",
      "Best val Acc: 0.863400\n"
     ]
    }
   ],
   "source": [
    "model, _ = train_model(model, {\"train\": trainloader, \"val\": valloader}, criterion, optimizer, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  0.9922,  0.9922,  ...,  0.9922,  0.9922,  0.9922],\n",
      "          [ 1.0000,  0.9922,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  0.9922,  0.9922,  ...,  0.9922,  0.9922,  0.9922],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  0.9922,  1.0000,  ...,  0.9922,  0.9922,  0.9922],\n",
      "          [ 1.0000,  0.9922,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  0.9922,  0.9922,  ...,  0.9922,  0.9922,  0.9922],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  0.9922,  1.0000,  ...,  0.9922,  0.9922,  0.9922],\n",
      "          [ 1.0000,  0.9922,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  0.9922,  0.9922,  ...,  0.9922,  0.9922,  0.9922],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2627,  0.2941,  0.2941,  ...,  0.8667,  0.8275,  0.7961],\n",
      "          [-0.3569,  0.0118,  0.5059,  ...,  0.8275,  0.7882,  0.7490],\n",
      "          [-0.4275, -0.3961,  0.5922,  ...,  0.8353,  0.8039,  0.7725],\n",
      "          ...,\n",
      "          [ 0.1608,  0.0431,  0.0275,  ...,  0.5608,  0.5529,  0.5373],\n",
      "          [ 0.3490,  0.2784,  0.2314,  ...,  0.5608,  0.5451,  0.5373],\n",
      "          [ 0.5294,  0.3725,  0.2235,  ...,  0.4745,  0.4510,  0.4275]],\n",
      "\n",
      "         [[ 0.3176,  0.3176,  0.3020,  ...,  0.8431,  0.8353,  0.8118],\n",
      "          [-0.3255, -0.0275,  0.4431,  ...,  0.8118,  0.7804,  0.7490],\n",
      "          [-0.4275, -0.4824,  0.4510,  ...,  0.8118,  0.7882,  0.7569],\n",
      "          ...,\n",
      "          [ 0.1294,  0.0431,  0.0431,  ...,  0.5451,  0.5137,  0.4980],\n",
      "          [ 0.3569,  0.2784,  0.2314,  ...,  0.5843,  0.5451,  0.5216],\n",
      "          [ 0.5137,  0.3647,  0.2157,  ...,  0.4745,  0.4431,  0.4118]],\n",
      "\n",
      "         [[-0.1922, -0.2471, -0.3412,  ...,  0.7333,  0.7412,  0.7255],\n",
      "          [-0.6784, -0.3569,  0.0196,  ...,  0.7020,  0.6784,  0.6549],\n",
      "          [-0.6863, -0.6471,  0.2471,  ...,  0.7020,  0.6784,  0.6549],\n",
      "          ...,\n",
      "          [-0.1765, -0.2706, -0.2392,  ...,  0.3333,  0.2863,  0.2706],\n",
      "          [ 0.0902,  0.0196, -0.0353,  ...,  0.4353,  0.3882,  0.3569],\n",
      "          [ 0.4196,  0.2706,  0.1216,  ...,  0.4196,  0.3804,  0.3412]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7020,  0.7255,  0.7176,  ...,  0.5843,  0.5608,  0.5451],\n",
      "          [ 0.6941,  0.7176,  0.7098,  ...,  0.6157,  0.5922,  0.5686],\n",
      "          [ 0.7255,  0.7412,  0.7255,  ...,  0.6706,  0.6392,  0.6157],\n",
      "          ...,\n",
      "          [ 0.8118,  0.8196,  0.7569,  ...,  0.8275,  0.8353,  0.8196],\n",
      "          [ 0.7882,  0.8353,  0.7804,  ...,  0.8118,  0.8118,  0.8118],\n",
      "          [ 0.7804,  0.8118,  0.8118,  ...,  0.7412,  0.7647,  0.7333]],\n",
      "\n",
      "         [[ 0.9137,  0.9373,  0.9294,  ...,  0.9294,  0.9216,  0.9137],\n",
      "          [ 0.8745,  0.9059,  0.8980,  ...,  0.9137,  0.9059,  0.8980],\n",
      "          [ 0.8824,  0.8980,  0.8824,  ...,  0.9373,  0.9216,  0.9137],\n",
      "          ...,\n",
      "          [ 0.5843,  0.5843,  0.5216,  ...,  0.6392,  0.6471,  0.6392],\n",
      "          [ 0.5765,  0.6235,  0.5686,  ...,  0.6235,  0.6235,  0.6157],\n",
      "          [ 0.5529,  0.5765,  0.5843,  ...,  0.5451,  0.5686,  0.5373]],\n",
      "\n",
      "         [[ 0.9608,  0.9922,  0.9843,  ...,  0.9686,  0.9608,  0.9608],\n",
      "          [ 0.9216,  0.9451,  0.9373,  ...,  0.9529,  0.9451,  0.9451],\n",
      "          [ 0.9294,  0.9451,  0.9294,  ...,  0.9765,  0.9686,  0.9608],\n",
      "          ...,\n",
      "          [ 0.2863,  0.2706,  0.2078,  ...,  0.3725,  0.3804,  0.3725],\n",
      "          [ 0.2706,  0.3098,  0.2627,  ...,  0.3490,  0.3490,  0.3412],\n",
      "          [ 0.2627,  0.2784,  0.2784,  ...,  0.2314,  0.2627,  0.2314]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4118, -0.4353, -0.1765,  ..., -0.8824, -0.8980, -0.8824],\n",
      "          [-0.2784, -0.1451, -0.0118,  ..., -0.8745, -0.8824, -0.8118],\n",
      "          [-0.3098, -0.0039,  0.1843,  ..., -0.8431, -0.8902, -0.8196],\n",
      "          ...,\n",
      "          [-0.6784, -0.7569, -0.8039,  ..., -0.8667, -0.8353, -0.8275],\n",
      "          [-0.6157, -0.6706, -0.7490,  ..., -0.6314, -0.8353, -0.8275],\n",
      "          [-0.4275, -0.4510, -0.4510,  ...,  0.5059, -0.0431, -0.5529]],\n",
      "\n",
      "         [[-0.3333, -0.2706, -0.0118,  ..., -0.9216, -0.9373, -0.9137],\n",
      "          [-0.1529,  0.0039,  0.1137,  ..., -0.9216, -0.9451, -0.8353],\n",
      "          [-0.1843,  0.1059,  0.3020,  ..., -0.8980, -0.9686, -0.8510],\n",
      "          ...,\n",
      "          [-0.7333, -0.7961, -0.8431,  ..., -0.8039, -0.7725, -0.8196],\n",
      "          [-0.7333, -0.7882, -0.8588,  ..., -0.5922, -0.7961, -0.7804],\n",
      "          [-0.5059, -0.5294, -0.5686,  ...,  0.5137, -0.0353, -0.4980]],\n",
      "\n",
      "         [[-0.4902, -0.4431, -0.1373,  ..., -0.7961, -0.8118, -0.7961],\n",
      "          [-0.4902, -0.4196, -0.2941,  ..., -0.8039, -0.8196, -0.7725],\n",
      "          [-0.4745, -0.3255, -0.3255,  ..., -0.8118, -0.8275, -0.8039],\n",
      "          ...,\n",
      "          [-0.6549, -0.7098, -0.7412,  ..., -0.7647, -0.7490, -0.7490],\n",
      "          [-0.5922, -0.6392, -0.7098,  ..., -0.5529, -0.7647, -0.7569],\n",
      "          [-0.4667, -0.4510, -0.4431,  ...,  0.5451, -0.0039, -0.5059]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0745,  0.0745,  0.0824,  ...,  0.0196,  0.0118,  0.0039],\n",
      "          [ 0.1216,  0.1137,  0.1216,  ...,  0.0510,  0.0431,  0.0353],\n",
      "          [ 0.1686,  0.1451,  0.1451,  ...,  0.0745,  0.0588,  0.0667],\n",
      "          ...,\n",
      "          [ 0.7255,  0.5686,  0.6078,  ...,  0.6863,  0.6627,  0.6627],\n",
      "          [ 0.7098,  0.4353,  0.4118,  ...,  0.7020,  0.6863,  0.6784],\n",
      "          [ 0.7961,  0.7412,  0.7176,  ...,  0.7020,  0.6863,  0.6784]],\n",
      "\n",
      "         [[ 0.0824,  0.0824,  0.0902,  ..., -0.0118, -0.0196, -0.0275],\n",
      "          [ 0.1373,  0.1294,  0.1451,  ...,  0.0275,  0.0196,  0.0118],\n",
      "          [ 0.2078,  0.1765,  0.1765,  ...,  0.0667,  0.0588,  0.0667],\n",
      "          ...,\n",
      "          [ 0.7725,  0.6000,  0.6235,  ...,  0.7020,  0.6863,  0.6863],\n",
      "          [ 0.7490,  0.4667,  0.4353,  ...,  0.7255,  0.7098,  0.7020],\n",
      "          [ 0.8353,  0.7647,  0.7333,  ...,  0.7333,  0.7176,  0.7098]],\n",
      "\n",
      "         [[-0.1843, -0.1843, -0.1765,  ..., -0.2706, -0.2784, -0.2863],\n",
      "          [-0.1294, -0.1373, -0.1216,  ..., -0.2314, -0.2392, -0.2471],\n",
      "          [-0.0745, -0.0980, -0.0980,  ..., -0.1922, -0.2078, -0.2078],\n",
      "          ...,\n",
      "          [ 0.5765,  0.3961,  0.4118,  ...,  0.4980,  0.4824,  0.4824],\n",
      "          [ 0.5843,  0.2627,  0.2000,  ...,  0.5451,  0.5373,  0.5294],\n",
      "          [ 0.6784,  0.5765,  0.5137,  ...,  0.5843,  0.5686,  0.5529]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  0.9922,  1.0000,  ..., -0.0588, -0.1059, -0.0745],\n",
      "          [ 0.9922,  0.9922,  1.0000,  ..., -0.0588, -0.1451, -0.1059],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ..., -0.0039, -0.1686, -0.1451],\n",
      "          ...,\n",
      "          [ 0.8980,  0.8980,  0.9216,  ...,  0.9529,  0.9373,  0.8745],\n",
      "          [ 0.8980,  0.8980,  0.9216,  ...,  0.9529,  0.9843,  0.9294],\n",
      "          [ 0.8745,  0.8980,  0.9216,  ...,  0.9529,  0.9765,  0.9843]],\n",
      "\n",
      "         [[ 0.9216,  0.9373,  0.9529,  ..., -0.4275, -0.4745, -0.4667],\n",
      "          [ 0.9137,  0.9373,  0.9529,  ..., -0.4118, -0.4824, -0.4667],\n",
      "          [ 0.9216,  0.9451,  0.9608,  ..., -0.3490, -0.4902, -0.4980],\n",
      "          ...,\n",
      "          [ 0.1608,  0.1529,  0.1765,  ...,  0.3569,  0.3490,  0.3176],\n",
      "          [ 0.1608,  0.1608,  0.1843,  ...,  0.3569,  0.4039,  0.3333],\n",
      "          [ 0.1686,  0.1608,  0.2000,  ...,  0.3647,  0.4196,  0.4196]],\n",
      "\n",
      "         [[ 0.0353,  0.0510,  0.0745,  ..., -0.7725, -0.7961, -0.7882],\n",
      "          [ 0.0275,  0.0431,  0.0745,  ..., -0.7804, -0.7882, -0.7882],\n",
      "          [ 0.0353,  0.0588,  0.0745,  ..., -0.7725, -0.7961, -0.7961],\n",
      "          ...,\n",
      "          [-0.4980, -0.4902, -0.4745,  ..., -0.3882, -0.4275, -0.4824],\n",
      "          [-0.4980, -0.5059, -0.4745,  ..., -0.3725, -0.3725, -0.4745],\n",
      "          [-0.4980, -0.5059, -0.4902,  ..., -0.3804, -0.3647, -0.4039]]]])\n",
      "-----------------------------\n",
      "tensor([[[[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  0.9996,  ...,  0.9983,  0.9983,  0.9983],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  0.9996,  ...,  0.9983,  0.9983,  0.9983],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  0.9996,  ...,  0.9983,  0.9983,  0.9983],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  0.9996,  ...,  0.9983,  0.9983,  0.9983],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]],\n",
      "\n",
      "         [[ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  0.9996,  ...,  0.9983,  0.9983,  0.9983],\n",
      "          ...,\n",
      "          [ 1.0000,  1.0000,  0.9996,  ...,  0.9983,  0.9983,  0.9983],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "          [ 1.0000,  1.0000,  1.0000,  ...,  1.0000,  1.0000,  1.0000]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2627,  0.2627,  0.2695,  ...,  0.8028,  0.7961,  0.7961],\n",
      "          [ 0.2627,  0.2627,  0.2695,  ...,  0.8028,  0.7961,  0.7961],\n",
      "          [ 0.1300,  0.1300,  0.1522,  ...,  0.7931,  0.7860,  0.7860],\n",
      "          ...,\n",
      "          [ 0.4908,  0.4908,  0.4611,  ...,  0.4553,  0.4510,  0.4510],\n",
      "          [ 0.5294,  0.5294,  0.4958,  ...,  0.4325,  0.4275,  0.4275],\n",
      "          [ 0.5294,  0.5294,  0.4958,  ...,  0.4325,  0.4275,  0.4275]],\n",
      "\n",
      "         [[ 0.3176,  0.3176,  0.3176,  ...,  0.8168,  0.8118,  0.8118],\n",
      "          [ 0.3176,  0.3176,  0.3176,  ...,  0.8168,  0.8118,  0.8118],\n",
      "          [ 0.1798,  0.1798,  0.1935,  ...,  0.8037,  0.7983,  0.7983],\n",
      "          ...,\n",
      "          [ 0.4801,  0.4801,  0.4514,  ...,  0.4417,  0.4353,  0.4353],\n",
      "          [ 0.5137,  0.5137,  0.4818,  ...,  0.4185,  0.4118,  0.4118],\n",
      "          [ 0.5137,  0.5137,  0.4818,  ...,  0.4185,  0.4118,  0.4118]],\n",
      "\n",
      "         [[-0.1922, -0.1922, -0.2039,  ...,  0.7289,  0.7255,  0.7255],\n",
      "          [-0.1922, -0.1922, -0.2039,  ...,  0.7289,  0.7255,  0.7255],\n",
      "          [-0.2964, -0.2964, -0.2908,  ...,  0.7141,  0.7104,  0.7104],\n",
      "          ...,\n",
      "          [ 0.3490,  0.3490,  0.3207,  ...,  0.3526,  0.3445,  0.3445],\n",
      "          [ 0.4196,  0.4196,  0.3877,  ...,  0.3496,  0.3412,  0.3412],\n",
      "          [ 0.4196,  0.4196,  0.3877,  ...,  0.3496,  0.3412,  0.3412]]],\n",
      "\n",
      "\n",
      "        [[[ 0.7020,  0.7020,  0.7070,  ...,  0.5485,  0.5451,  0.5451],\n",
      "          [ 0.7020,  0.7020,  0.7070,  ...,  0.5485,  0.5451,  0.5451],\n",
      "          [ 0.7003,  0.7003,  0.7053,  ...,  0.5539,  0.5501,  0.5501],\n",
      "          ...,\n",
      "          [ 0.7821,  0.7821,  0.7895,  ...,  0.7554,  0.7501,  0.7501],\n",
      "          [ 0.7804,  0.7804,  0.7871,  ...,  0.7401,  0.7333,  0.7333],\n",
      "          [ 0.7804,  0.7804,  0.7871,  ...,  0.7401,  0.7333,  0.7333]],\n",
      "\n",
      "         [[ 0.9137,  0.9137,  0.9188,  ...,  0.9154,  0.9137,  0.9137],\n",
      "          [ 0.9137,  0.9137,  0.9188,  ...,  0.9154,  0.9137,  0.9137],\n",
      "          [ 0.9053,  0.9053,  0.9107,  ...,  0.9120,  0.9104,  0.9104],\n",
      "          ...,\n",
      "          [ 0.5580,  0.5580,  0.5641,  ...,  0.5597,  0.5541,  0.5541],\n",
      "          [ 0.5529,  0.5529,  0.5580,  ...,  0.5440,  0.5373,  0.5373],\n",
      "          [ 0.5529,  0.5529,  0.5580,  ...,  0.5440,  0.5373,  0.5373]],\n",
      "\n",
      "         [[ 0.9608,  0.9608,  0.9675,  ...,  0.9608,  0.9608,  0.9608],\n",
      "          [ 0.9608,  0.9608,  0.9675,  ...,  0.9608,  0.9608,  0.9608],\n",
      "          [ 0.9524,  0.9524,  0.9587,  ...,  0.9574,  0.9574,  0.9574],\n",
      "          ...,\n",
      "          [ 0.2644,  0.2644,  0.2689,  ...,  0.2605,  0.2549,  0.2549],\n",
      "          [ 0.2627,  0.2627,  0.2661,  ...,  0.2381,  0.2314,  0.2314],\n",
      "          [ 0.2627,  0.2627,  0.2661,  ...,  0.2381,  0.2314,  0.2314]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.4118, -0.4118, -0.4168,  ..., -0.8857, -0.8824, -0.8824],\n",
      "          [-0.4118, -0.4118, -0.4168,  ..., -0.8857, -0.8824, -0.8824],\n",
      "          [-0.3832, -0.3832, -0.3810,  ..., -0.8731, -0.8672, -0.8672],\n",
      "          ...,\n",
      "          [-0.4678, -0.4678, -0.4743,  ..., -0.5263, -0.6118, -0.6118],\n",
      "          [-0.4275, -0.4275, -0.4325,  ..., -0.4437, -0.5529, -0.5529],\n",
      "          [-0.4275, -0.4275, -0.4325,  ..., -0.4437, -0.5529, -0.5529]],\n",
      "\n",
      "         [[-0.3333, -0.3333, -0.3199,  ..., -0.9188, -0.9137, -0.9137],\n",
      "          [-0.3333, -0.3333, -0.3199,  ..., -0.9188, -0.9137, -0.9137],\n",
      "          [-0.2947, -0.2947, -0.2769,  ..., -0.9059, -0.8969, -0.8969],\n",
      "          ...,\n",
      "          [-0.5546, -0.5546, -0.5611,  ..., -0.4814, -0.5585, -0.5585],\n",
      "          [-0.5059, -0.5059, -0.5109,  ..., -0.3989, -0.4980, -0.4980],\n",
      "          [-0.5059, -0.5059, -0.5109,  ..., -0.3989, -0.4980, -0.4980]],\n",
      "\n",
      "         [[-0.4902, -0.4902, -0.4801,  ..., -0.7994, -0.7961, -0.7961],\n",
      "          [-0.4902, -0.4902, -0.4801,  ..., -0.7994, -0.7961, -0.7961],\n",
      "          [-0.4902, -0.4902, -0.4790,  ..., -0.7958, -0.7910, -0.7910],\n",
      "          ...,\n",
      "          [-0.4936, -0.4936, -0.4931,  ..., -0.4755, -0.5597, -0.5597],\n",
      "          [-0.4667, -0.4667, -0.4633,  ..., -0.3983, -0.5059, -0.5059],\n",
      "          [-0.4667, -0.4667, -0.4633,  ..., -0.3983, -0.5059, -0.5059]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0745,  0.0745,  0.0745,  ...,  0.0056,  0.0039,  0.0039],\n",
      "          [ 0.0745,  0.0745,  0.0745,  ...,  0.0056,  0.0039,  0.0039],\n",
      "          [ 0.0846,  0.0846,  0.0842,  ...,  0.0123,  0.0106,  0.0106],\n",
      "          ...,\n",
      "          [ 0.7776,  0.7776,  0.7557,  ...,  0.6801,  0.6784,  0.6784],\n",
      "          [ 0.7961,  0.7961,  0.7843,  ...,  0.6801,  0.6784,  0.6784],\n",
      "          [ 0.7961,  0.7961,  0.7843,  ...,  0.6801,  0.6784,  0.6784]],\n",
      "\n",
      "         [[ 0.0824,  0.0824,  0.0824,  ..., -0.0258, -0.0275, -0.0275],\n",
      "          [ 0.0824,  0.0824,  0.0824,  ..., -0.0258, -0.0275, -0.0275],\n",
      "          [ 0.0941,  0.0941,  0.0938,  ..., -0.0174, -0.0190, -0.0190],\n",
      "          ...,\n",
      "          [ 0.8168,  0.8168,  0.7920,  ...,  0.7098,  0.7081,  0.7081],\n",
      "          [ 0.8353,  0.8353,  0.8202,  ...,  0.7115,  0.7098,  0.7098],\n",
      "          [ 0.8353,  0.8353,  0.8202,  ...,  0.7115,  0.7098,  0.7098]],\n",
      "\n",
      "         [[-0.1843, -0.1843, -0.1843,  ..., -0.2846, -0.2863, -0.2863],\n",
      "          [-0.1843, -0.1843, -0.1843,  ..., -0.2846, -0.2863, -0.2863],\n",
      "          [-0.1725, -0.1725, -0.1729,  ..., -0.2762, -0.2779, -0.2779],\n",
      "          ...,\n",
      "          [ 0.6583,  0.6583,  0.6263,  ...,  0.5509,  0.5479,  0.5479],\n",
      "          [ 0.6784,  0.6784,  0.6566,  ...,  0.5563,  0.5529,  0.5529],\n",
      "          [ 0.6784,  0.6784,  0.6566,  ...,  0.5563,  0.5529,  0.5529]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0000,  1.0000,  0.9983,  ..., -0.0812, -0.0745, -0.0745],\n",
      "          [ 1.0000,  1.0000,  0.9983,  ..., -0.0812, -0.0745, -0.0745],\n",
      "          [ 0.9983,  0.9983,  0.9970,  ..., -0.0883, -0.0812, -0.0812],\n",
      "          ...,\n",
      "          [ 0.8796,  0.8796,  0.8835,  ...,  0.9737,  0.9725,  0.9725],\n",
      "          [ 0.8745,  0.8745,  0.8796,  ...,  0.9826,  0.9843,  0.9843],\n",
      "          [ 0.8745,  0.8745,  0.8796,  ...,  0.9826,  0.9843,  0.9843]],\n",
      "\n",
      "         [[ 0.9216,  0.9216,  0.9249,  ..., -0.4683, -0.4667, -0.4667],\n",
      "          [ 0.9216,  0.9216,  0.9249,  ..., -0.4683, -0.4667, -0.4667],\n",
      "          [ 0.9199,  0.9199,  0.9236,  ..., -0.4687, -0.4667, -0.4667],\n",
      "          ...,\n",
      "          [ 0.1669,  0.1669,  0.1656,  ...,  0.4044,  0.4011,  0.4011],\n",
      "          [ 0.1686,  0.1686,  0.1669,  ...,  0.4196,  0.4196,  0.4196],\n",
      "          [ 0.1686,  0.1686,  0.1669,  ...,  0.4196,  0.4196,  0.4196]],\n",
      "\n",
      "         [[ 0.0353,  0.0353,  0.0387,  ..., -0.7899, -0.7882, -0.7882],\n",
      "          [ 0.0353,  0.0353,  0.0387,  ..., -0.7899, -0.7882, -0.7882],\n",
      "          [ 0.0336,  0.0336,  0.0370,  ..., -0.7896, -0.7882, -0.7882],\n",
      "          ...,\n",
      "          [-0.4980, -0.4980, -0.4997,  ..., -0.4078, -0.4190, -0.4190],\n",
      "          [-0.4980, -0.4980, -0.4997,  ..., -0.3955, -0.4039, -0.4039],\n",
      "          [-0.4980, -0.4980, -0.4997,  ..., -0.3955, -0.4039, -0.4039]]]])\n"
     ]
    }
   ],
   "source": [
    "for inputs, labels in trainloader:\n",
    "    print(inputs)\n",
    "    print('-----------------------------')\n",
    "    print(transforms.functional.resize(inputs, (112, 112)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d07921fcac9efc71e32baa62f54cc7cc7703180b766de90eef3b067ead514a11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
